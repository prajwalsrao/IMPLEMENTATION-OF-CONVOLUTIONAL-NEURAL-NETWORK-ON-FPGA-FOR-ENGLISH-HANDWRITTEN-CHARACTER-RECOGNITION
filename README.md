The implementation of 2 Dimensional Convolutional Neural Networks (CNNs) on Field Programmable Gate Arrays (FPGAs) has gained significant attention in recent years due to the increasing demand for high-performance computing systems. FPGA-based implementations of CNNs offer several advantages such as decreased latency, increased throughput, and reduced power consumption. This work presents a methodology for implementing a 2D CNN on an FPGA to reduce latency and area utilization and not compromise the accuracy of the model. Various techniques were explored for optimizing the design for time and area, including pipelining, parallelization, and resource sharing. The experimental results show that the proposed methodology provides significant improvements in both latency and area utilization, making it an attractive option for high-performance CNN implementations.

A Convolutional neural network majorly consists of 2D Convolution layers and Max-pooling layers. In a life-cycle of a CNN, the majority of the time is spent in 2D convolution whether itâ€˜s spent on training or while predicting. This work presents an implementation of 2D CNN on FPGA. An FPGA-based system is designed with a novel architecture that combines 2D convolution and pooling followed by fully connected layers to achieve an efficient implementation. The architecture is optimized for computational efficiency by exploiting the inherent parallelism of the FPGA, which makes it suitable for real-time applications.

The proposed 2D CNN is tested on a handwritten character recognition data set and the results show that it achieves a high accuracy rate and runs in real-time. The proposed system is compared with a CNN and is shown to be more efficient and accurate. The results show that FPGA-based 2D CNN is a valuable tool for real-time application
